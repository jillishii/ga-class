{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Final Project: Etsy Marketplace Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import HTML tools\n",
    "from lxml import html\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in the list of etsy page categories\n",
    "import pandas as pd\n",
    "etsy_pages = pd.read_csv(\"etsy_category_pages.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page_cat = etsy_pages['page'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate list of urls for each category\n",
    "\n",
    "urls = []\n",
    "start = \"https://www.etsy.com/c/\"\n",
    "\n",
    "for x in page_cat:\n",
    "    urls.append(start + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accessories', <Response [200]>),\n",
       " ('bags-and-purses', <Response [200]>),\n",
       " ('clothing', <Response [200]>),\n",
       " ('shoes', <Response [200]>),\n",
       " ('jewelry', <Response [200]>),\n",
       " ('craft-supplies-and-tools', <Response [200]>),\n",
       " ('weddings', <Response [200]>),\n",
       " ('books-movies-and-music', <Response [200]>),\n",
       " ('electronics-and-accessories', <Response [200]>),\n",
       " ('toys-and-games', <Response [200]>),\n",
       " ('art-and-collectibles', <Response [200]>),\n",
       " ('bath-and-beauty', <Response [200]>),\n",
       " ('home-and-living', <Response [200]>),\n",
       " ('paper-and-party-supplies', <Response [200]>),\n",
       " ('pet-supplies', <Response [200]>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the urls have a page associated with them?\n",
    "import requests\n",
    "page_response2 = []\n",
    "page = \"\"\n",
    "for x in urls:\n",
    "    page = requests.get(x)\n",
    "    page_response2.append(page)\n",
    "    \n",
    "zip(page_cat,page_response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All of these categories get a successful response \n",
    "# Now that we have a list of catgories with associated web pages, we can scrape subcategories\n",
    "# After we collect subcategores we can get the shop names from each subcategory page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all html elements which contain the links to the subcategory pages\n",
    "import lxml\n",
    "sub_elements = []\n",
    "\n",
    "for url in urls:\n",
    "    #send the request\n",
    "    content = requests.get(url)\n",
    "    #save the page source code to a string called content_string\n",
    "    content_string = content.text.encode(\"utf-8\")\n",
    "    #pass the page source to our html parse\n",
    "    doc = lxml.html.document_fromstring(content_string)\n",
    "    # Find html element containing each subcategory\n",
    "    element = doc.xpath(\"//li[@class='pb-xs-1 pl-xs-0']\")\n",
    "    sub_elements.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get urls for each of the subcategories and store them in a list\n",
    "sub_links = []\n",
    "\n",
    "for element in sub_elements:\n",
    "    for x in element:\n",
    "        child = x.getchildren()\n",
    "        new = child[0].attrib['href']\n",
    "        sub_links.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save subcategory links in a csv file\n",
    "import csv\n",
    "\n",
    "with open('subcategory_links.csv', 'w') as csvfile:\n",
    "    fieldnames=['link']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # iterate through category and subcategory\n",
    "    for item in sub_links:\n",
    "        writer.writerow({'link': item})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open csv subcategory link file\n",
    "newdata = pd.read_csv(\"subcategory_links.csv\",sep=\"/\",names=('0','1','2','3','top_category','link_address'))\n",
    "del(newdata['0'],newdata['1'],newdata['2'],newdata['3'])\n",
    "catdf = newdata.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract subcatgory name from link and save as new csv file\n",
    "def clean_links(text):\n",
    "    return text.split(\"?\")[0]\n",
    "\n",
    "catdf['sub_category'] = catdf['link_address'].apply(clean_links)\n",
    "catdf.to_csv(path_or_buf = \"category_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_links = pd.read_csv(\"subcategory_links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_links['source'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get source code for every subcategory link and append to the sub_links dataframe    \n",
    "for i in range(len(sub_links)):\n",
    "    content = sub_links['link'][i]\n",
    "    source_code = requests.get(content)\n",
    "    source_string = source_code.text.encode(\"utf-8\")\n",
    "    sub_links['source'][i] = source_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join dataframes\n",
    "\n",
    "catdf = catdf.reset_index()\n",
    "catdf = catdf.join(sub_links)\n",
    "del catdf['index']\n",
    "del catdf['link_address']\n",
    "#catdf = catdf.set_index(['sub_category'], drop = False)\n",
    "\n",
    "catdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# finds all shop names from html source string and appends to list\n",
    "# returns list\n",
    "\n",
    "def get_shop_names(source_string):\n",
    "    j = []\n",
    "    doc = lxml.html.document_fromstring(source_string)\n",
    "    tags = doc.xpath(\"//div[@class='card-meta-row-item text-truncate overflow-hidden card-shop-name']\")\n",
    "    for tag in tags:\n",
    "        j.append(tag.text)\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new column to store list of shop names\n",
    "catdf['shops'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# populate column with list of shop names\n",
    "for i in range(len(catdf)):\n",
    "    l = get_shop_names(catdf['source'][i])\n",
    "    catdf['shops'][i] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes raw list containing shop names\n",
    "#returns clean list with shop name only\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_name(messy_name_list):\n",
    "    new_list = []\n",
    "    for name in messy_name_list:\n",
    "        finder = re.compile(\"\\n\" + \"(.*?)\" + \"\\n\", re.IGNORECASE)\n",
    "        matches = finder.findall(name)\n",
    "        no_replace = re.compile(\"\\s+\")\n",
    "        p = no_replace.sub(\"\", matches[0])\n",
    "        new_list.append(p)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply function to every list in column 'shops'\n",
    "for i in range(len(catdf)):\n",
    "    catdf['shops'][i] = clean_name(catdf['shops'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catdf['review_links'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "catdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate urls for each shop name in the list\n",
    "\n",
    "for i in range(len(catdf)):\n",
    "    urls = []\n",
    "    for x in catdf['shops'][i]:\n",
    "        urls.append(\"https://www.etsy.com/shop/\"+ x +\"/reviews\")\n",
    "    catdf['review_links'][i] = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(catdf['review_links'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_elements = []\n",
    "a_elements = []\n",
    "review_dates = []    \n",
    "def review_dates_per_shop(i,j):\n",
    "    shop = catdf['review_links'][i][j]\n",
    "    content = requests.get(shop)\n",
    "    content_string = content.text.encode(\"utf-8\")\n",
    "    doc = lxml.html.document_fromstring(content_string)\n",
    "    tags = doc.xpath(\"//div[@class='mt-xs-2 mb-xs-2']\")\n",
    "    for tag in tags:\n",
    "        p_elements.append(tag.getchildren())\n",
    "    for p in p_elements:\n",
    "        for x in p:\n",
    "            a_elements.append(x.getchildren())\n",
    "    for element in a_elements:\n",
    "        for x in element:\n",
    "            review_dates.append(x.tail)\n",
    "    return {catdf['shops'][i][j] : review_dates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = review_dates_per_shop(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new2 = review_dates_per_shop(0,1)\n",
    "new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    #date_list = []\n",
    "    x = review_dates_per_shop(0,i)\n",
    "    #date_list.append(x)\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catdf['shop_review_dates'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pull_dates(m,n):\n",
    "    while n < 43:\n",
    "        my_dict = review_dates_per_shop(m,n)\n",
    "        poop.append(my_dict)\n",
    "        n =+ 1\n",
    "    return poop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
